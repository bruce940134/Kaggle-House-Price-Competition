{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import cross_validate\n#from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nimport xgboost as xgb\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import StackingRegressor\n#from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n#from sklearn.pipeline import make_pipeline\n#from sklearn.preprocessing import StandardScaler\n#from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.cluster import KMeans\n\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import StackingClassifier\n\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.feature_selection import mutual_info_regression\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-05T22:50:44.414227Z","iopub.execute_input":"2022-04-05T22:50:44.414714Z","iopub.status.idle":"2022-04-05T22:50:45.703187Z","shell.execute_reply.started":"2022-04-05T22:50:44.414560Z","shell.execute_reply":"2022-04-05T22:50:45.702126Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\ntest_data = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.705219Z","iopub.execute_input":"2022-04-05T22:50:45.705734Z","iopub.status.idle":"2022-04-05T22:50:45.762360Z","shell.execute_reply.started":"2022-04-05T22:50:45.705693Z","shell.execute_reply":"2022-04-05T22:50:45.761424Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"m = train_data.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.763437Z","iopub.execute_input":"2022-04-05T22:50:45.763696Z","iopub.status.idle":"2022-04-05T22:50:45.768427Z","shell.execute_reply.started":"2022-04-05T22:50:45.763656Z","shell.execute_reply":"2022-04-05T22:50:45.767456Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfor col in train_data.columns:\n    null_percent = train_data[col].isnull().sum() / m\n    if null_percent > 0:\n        print(col)\n        print(null_percent)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.770059Z","iopub.execute_input":"2022-04-05T22:50:45.770945Z","iopub.status.idle":"2022-04-05T22:50:45.783352Z","shell.execute_reply.started":"2022-04-05T22:50:45.770906Z","shell.execute_reply":"2022-04-05T22:50:45.782416Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Drop columns with too many missing data and no impact on the sale price\ntrain_data = train_data.drop(columns=[\"Id\"])\ntest_data = test_data.drop(columns=[\"Id\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.785613Z","iopub.execute_input":"2022-04-05T22:50:45.786070Z","iopub.status.idle":"2022-04-05T22:50:45.800002Z","shell.execute_reply.started":"2022-04-05T22:50:45.786011Z","shell.execute_reply":"2022-04-05T22:50:45.799010Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_y = train_data['SalePrice']\ntrain_X = train_data.drop(columns=['SalePrice'])\nall_data = pd.concat([train_X, test_data],ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.801499Z","iopub.execute_input":"2022-04-05T22:50:45.802102Z","iopub.status.idle":"2022-04-05T22:50:45.828697Z","shell.execute_reply.started":"2022-04-05T22:50:45.802058Z","shell.execute_reply":"2022-04-05T22:50:45.827945Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"num_col = list(all_data.select_dtypes(include=['int','float']).columns)\nobj_col = list(all_data.select_dtypes(include=['object']).columns)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.830048Z","iopub.execute_input":"2022-04-05T22:50:45.830469Z","iopub.status.idle":"2022-04-05T22:50:45.847613Z","shell.execute_reply.started":"2022-04-05T22:50:45.830434Z","shell.execute_reply":"2022-04-05T22:50:45.846222Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Specific pre-processing columns","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.849115Z","iopub.execute_input":"2022-04-05T22:50:45.849910Z","iopub.status.idle":"2022-04-05T22:50:45.854318Z","shell.execute_reply.started":"2022-04-05T22:50:45.849866Z","shell.execute_reply":"2022-04-05T22:50:45.853149Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n# Columns with meaningful nan: \n# Alley, GarageType, GarageQual, GarageCond, BsmtQual, BsmtCond, FireplaceQu, PoolQC, \n# BsmtFinType1, BsmtFinType2, BsmtExposure, GarageFinish, Fence, MiscFeature\nnan_col = ['Alley', 'GarageType', 'GarageQual', 'GarageCond',\n           'BsmtQual', 'BsmtCond', 'FireplaceQu', 'PoolQC', \n           'BsmtFinType1', 'BsmtFinType2', 'BsmtExposure',\n           'GarageFinish', 'Fence', 'MiscFeature', 'ExterQual', \n           'ExterCond', 'HeatingQC', 'KitchenQual', 'Functional']\nall_data[nan_col] = all_data[nan_col].fillna(0)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.855837Z","iopub.execute_input":"2022-04-05T22:50:45.856200Z","iopub.status.idle":"2022-04-05T22:50:45.871695Z","shell.execute_reply.started":"2022-04-05T22:50:45.856165Z","shell.execute_reply":"2022-04-05T22:50:45.870507Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# For categorical columns with some sort of hierarchy, rank from low to high, and specify if nan means something\n# Have to do this manually for both train and test,\n# since it's in the data description, and training data might not have all the values\n\n# Alley: nan = no alley access\n# GarageType: nan = no garage\n\n# ExterQual: Po -> Fa -> TA -> Gd -> Ex\n# ExterCond: Po -> Fa -> TA -> Gd -> Ex\n# HeatingQC: Po -> Fa -> TA -> Gd -> Ex\n# KitchenQual: Po -> Fa -> TA -> Gd -> Ex\n\n# GarageQual: nan -> Po -> Fa -> TA -> Gd -> Ex\n# GarageCond: nan -> Po -> Fa -> TA -> Gd -> Ex\n# BsmtQual: nan -> Po -> Fa -> TA -> Gd -> Ex\n# BsmtCond: nan -> Po -> Fa -> TA -> Gd -> Ex\n# FireplaceQu: nan -> Po -> Fa -> TA -> Gd -> Ex\n# PoolQC: nan -> Po -> Fa -> TA -> Gd -> Ex\n\n\n# BsmtFinType1: nan -> Unf -> LwQ -> Rec -> BLQ -> ALQ -> GLQ\n# BsmtFinType2: nan -> Unf -> LwQ -> Rec -> BLQ -> ALQ -> GLQ\n\n\n# LotShape: IR3 -> IR2 -> IR1 -> Reg\n# Utilities: ELO -> NoSeWa -> NoSeWr -> AllPub\n# LandSlope: Gtl -> Mod -> Sev\n# BldgType: 1Fam -> 2FmCon -> Duplx -> TwnhsE -> Twnhs\n# HouseStyle: 1Story -> 1.5Unf -> 1.5Fin -> 2Story -> 2.5Unf -> 2.5Fin -> SFoyer -> SLvl\n# BsmtExposure: nan -> No -> Mn -> Av -> Gd\n# Electrical: Mix -> FuseP -> FuseF -> FuseA -> SBrkr\n# Functional: Sal -> Sev -> Maj2 -> Maj1 -> Mod -> Min2 -> Min1 -> Typ\n# GarageFinish: nan -> Unf -> RFn -> Fin\n# PavedDrive: N -> P -> Y\n# Fence: nan -> MnWw -> GdWo -> MnPrv -> GdPrv\n\n\n\"\"\"\nfor val in train_data['SaleCondition'].unique():\n    print(val)\n    mean = train_data.loc[train_data['SaleCondition'] == val, 'SalePrice'].mean()\n    print(mean)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.873601Z","iopub.execute_input":"2022-04-05T22:50:45.873904Z","iopub.status.idle":"2022-04-05T22:50:45.885694Z","shell.execute_reply.started":"2022-04-05T22:50:45.873870Z","shell.execute_reply":"2022-04-05T22:50:45.884905Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\"\"\"\no_val1 = ['Po', 'Fa', 'TA', 'Gd', 'Ex']\no_col1 = ['ExterQual', 'ExterCond', 'HeatingQC', 'KitchenQual', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond', 'FireplaceQu', 'PoolQC']\no_col3 = ['BsmtFinType1', 'BsmtFinType2']\no_val2 = ['Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ']\no_col4 = ['LotShape', 'Utilities', 'LandSlope', 'BldgType',\n          'HouseStyle', 'BsmtExposure', 'Electrical', 'Functional', \n          'GarageFinish', 'PavedDrive', 'Fence']\no_val4 = [['IR3', 'IR2', 'IR1', 'Reg'], \n          ['ELO', 'NoSeWa', 'NoSeWr', 'AllPub'],\n          ['Gtl', 'Mod', 'Sev'], \n          ['1Fam', '2fmCon', 'Duplex', 'TwnhsE', 'Twnhs'],\n          ['1Story', '1.5Unf', '1.5Fin', '2Story', '2.5Unf', '2.5Fin', 'SFoyer', 'SLvl'],\n          [0, 'No', 'Mn', 'Av', 'Gd'],\n          ['Mix', 'FuseP', 'FuseF', 'FuseA', 'SBrkr'],\n          ['Sal', 'Sev', 'Maj2', 'Maj1', 'Mod', 'Min2', 'Min1', 'Typ'],\n          [0, 'Unf', 'RFn', 'Fin'],\n          ['N', 'P', 'Y'],\n          [0, 'MnWw', 'GdWo', 'MnPrv', 'GdPrv']]\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.887002Z","iopub.execute_input":"2022-04-05T22:50:45.887804Z","iopub.status.idle":"2022-04-05T22:50:45.906751Z","shell.execute_reply.started":"2022-04-05T22:50:45.887759Z","shell.execute_reply":"2022-04-05T22:50:45.905797Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nall_data[o_col1+o_col3+o_col4] = all_data[o_col1+o_col3+o_col4].fillna(0)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.908552Z","iopub.execute_input":"2022-04-05T22:50:45.909467Z","iopub.status.idle":"2022-04-05T22:50:45.921531Z","shell.execute_reply.started":"2022-04-05T22:50:45.909412Z","shell.execute_reply":"2022-04-05T22:50:45.920870Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfor col in o_col1:\n    for i in range(len(o_val1)):\n        all_data.loc[all_data[col] == o_val1[i], col] = i+1\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.922677Z","iopub.execute_input":"2022-04-05T22:50:45.923098Z","iopub.status.idle":"2022-04-05T22:50:45.934445Z","shell.execute_reply.started":"2022-04-05T22:50:45.923065Z","shell.execute_reply":"2022-04-05T22:50:45.933534Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfor col in o_col3:\n    for i in range(len(o_val2)):\n        all_data.loc[all_data[col] == o_val2[i], col] = i+1\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.938206Z","iopub.execute_input":"2022-04-05T22:50:45.938495Z","iopub.status.idle":"2022-04-05T22:50:45.947533Z","shell.execute_reply.started":"2022-04-05T22:50:45.938461Z","shell.execute_reply":"2022-04-05T22:50:45.946816Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfor i in range(len(o_col4)):\n    col = o_col4[i]\n    val_col = o_val4[i]\n    for j in range(len(val_col)):\n        all_data.loc[all_data[col] == val_col[j], col] = j+1\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.948934Z","iopub.execute_input":"2022-04-05T22:50:45.949406Z","iopub.status.idle":"2022-04-05T22:50:45.961348Z","shell.execute_reply.started":"2022-04-05T22:50:45.949371Z","shell.execute_reply":"2022-04-05T22:50:45.960656Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n# Check if functions ran corrrectly\nfor col in o_col1+o_col3+o_col4:\n    print(col)\n    print(all_data[col].unique())\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.962727Z","iopub.execute_input":"2022-04-05T22:50:45.963151Z","iopub.status.idle":"2022-04-05T22:50:45.976186Z","shell.execute_reply.started":"2022-04-05T22:50:45.963088Z","shell.execute_reply":"2022-04-05T22:50:45.975273Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nobj_col = list(all_data.drop(columns=o_col1+o_col3+o_col4).select_dtypes(include=['object']).columns)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.977766Z","iopub.execute_input":"2022-04-05T22:50:45.978737Z","iopub.status.idle":"2022-04-05T22:50:45.990377Z","shell.execute_reply.started":"2022-04-05T22:50:45.978686Z","shell.execute_reply":"2022-04-05T22:50:45.989672Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfor col in obj_col:\n    print(col)\n    print(all_data[col].unique())\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:45.992156Z","iopub.execute_input":"2022-04-05T22:50:45.992996Z","iopub.status.idle":"2022-04-05T22:50:46.004798Z","shell.execute_reply.started":"2022-04-05T22:50:45.992956Z","shell.execute_reply":"2022-04-05T22:50:46.003844Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n# Categorical columns that are missing some values in both the dataset compared to the data description\n# MSZoning, Condition1, Condition2, Exterior1st, Exterior2nd, MiscFeature, SaleType\n# Transform to labels based on data description\no_col5 = ['MSZoning', 'Condition1', 'Condition2', 'Exterior1st', 'Exterior2nd', 'MiscFeature', 'SaleType']\no_val5 = [['A', 'C (all)', 'FV', 'I', 'RH', 'RL', 'RP', 'RM'],\n          ['Artery', 'Feedr', 'Norm', 'RRNn', 'RRAn', 'PosN', 'PosA', 'RRNe', 'RRAe'],\n          ['Artery', 'Feedr', 'Norm', 'RRNn', 'RRAn', 'PosN', 'PosA', 'RRNe', 'RRAe'],\n          ['AsbShng', 'AsphShn', 'BrkComm', 'BrkFace', 'CBlock', 'CemntBd', 'HdBoard',\n            'ImStucc', 'MetalSd', 'Other', 'Plywood', 'PreCast', 'Stone', 'Stucco',\n            'VinylSd', 'Wd Sdng', 'WdShing'],\n          ['AsbShng', 'AsphShn', 'BrkComm', 'BrkFace', 'CBlock', 'CemntBd', 'HdBoard',\n            'ImStucc', 'MetalSd', 'Other', 'Plywood', 'PreCast', 'Stone', 'Stucco',\n            'VinylSd', 'Wd Sdng', 'WdShing'],\n          [0, 'Elev', 'Gar2', 'Othr', 'Shed', 'TenC'],\n          ['WD', 'CWD', 'VWD', 'New', 'COD', 'Con', 'ConLw', 'ConLI', 'ConLD', 'Oth']]\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:46.006343Z","iopub.execute_input":"2022-04-05T22:50:46.006756Z","iopub.status.idle":"2022-04-05T22:50:46.020888Z","shell.execute_reply.started":"2022-04-05T22:50:46.006616Z","shell.execute_reply":"2022-04-05T22:50:46.019956Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfor i in range(len(o_col5)):\n    col = o_col5[i]\n    val_col = o_val5[i]\n    for j in range(len(val_col)):\n        all_data.loc[all_data[col] == val_col[j], col] = j\n    print(all_data[col].unique())\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:46.021978Z","iopub.execute_input":"2022-04-05T22:50:46.022740Z","iopub.status.idle":"2022-04-05T22:50:46.039286Z","shell.execute_reply.started":"2022-04-05T22:50:46.022684Z","shell.execute_reply":"2022-04-05T22:50:46.038619Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n# As shown above, column Exterior2nd contains wrong values\n# Changing the wrong values to the closest value on the data description\n# Wd Shng -> Wd Sdng -> 15th value in the list in o_val5 for Exterior2nd\n# CmentBd -> CemntBd -> 5th value in the list in o_val5 for Exterior2nd\n# Brk Cmn -> BrkComm -> 2nd value in the list in o_val5 for Exterior2nd\nall_data.loc[all_data['Exterior2nd'] == 'Wd Shng', 'Exterior2nd'] = 15\nall_data.loc[all_data['Exterior2nd'] == 'CmentBd', 'Exterior2nd'] = 5\nall_data.loc[all_data['Exterior2nd'] == 'Brk Cmn', 'Exterior2nd'] = 2\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:46.040342Z","iopub.execute_input":"2022-04-05T22:50:46.041206Z","iopub.status.idle":"2022-04-05T22:50:46.054819Z","shell.execute_reply.started":"2022-04-05T22:50:46.041165Z","shell.execute_reply":"2022-04-05T22:50:46.053443Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n# Check if above functions are working corectly\nfor col in o_col5:\n    print(col)\n    print(all_data[col].unique())\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:46.056173Z","iopub.execute_input":"2022-04-05T22:50:46.056929Z","iopub.status.idle":"2022-04-05T22:50:46.068459Z","shell.execute_reply.started":"2022-04-05T22:50:46.056874Z","shell.execute_reply":"2022-04-05T22:50:46.067673Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nobj_col = list(all_data.drop(columns=o_col1+o_col3+o_col4+o_col5).select_dtypes(include=['object']).columns)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:46.069858Z","iopub.execute_input":"2022-04-05T22:50:46.070229Z","iopub.status.idle":"2022-04-05T22:50:46.086692Z","shell.execute_reply.started":"2022-04-05T22:50:46.070196Z","shell.execute_reply":"2022-04-05T22:50:46.085850Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Transform the rest of the categorical data to numerical labels (ignoring null values for now)\nfor col in obj_col:\n    val = np.stack(train_data[col].unique())\n    for i in range(len(val)):\n        if (val[i] == 'nan') or (val[i] == 0):\n            val = np.delete(val, i)\n            break\n    for i in range(len(val)):\n        all_data.loc[all_data[col] == val[i], col] = i+1 \n        #test_data.loc[test_data[col] == val[i], col] = i+1","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:46.088085Z","iopub.execute_input":"2022-04-05T22:50:46.088366Z","iopub.status.idle":"2022-04-05T22:50:46.373613Z","shell.execute_reply.started":"2022-04-05T22:50:46.088333Z","shell.execute_reply":"2022-04-05T22:50:46.372771Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Check if all obj_col are labels\nobj_col = list(all_data.select_dtypes(include=['object']).columns)\nfor col in obj_col:\n    print(col)\n    print(all_data[col].unique())","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:46.374776Z","iopub.execute_input":"2022-04-05T22:50:46.375154Z","iopub.status.idle":"2022-04-05T22:50:46.423324Z","shell.execute_reply.started":"2022-04-05T22:50:46.375123Z","shell.execute_reply":"2022-04-05T22:50:46.422341Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Idea:\n# Use ML model to find missing values\n# Then use xgb to predict","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:46.426806Z","iopub.execute_input":"2022-04-05T22:50:46.427082Z","iopub.status.idle":"2022-04-05T22:50:46.432655Z","shell.execute_reply.started":"2022-04-05T22:50:46.427047Z","shell.execute_reply":"2022-04-05T22:50:46.431935Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# For each column:\n# Get null rows and drop other null columns\n# For every other row, drop null columns too\n# Use the other rows as train to predict the values of this column","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:46.433945Z","iopub.execute_input":"2022-04-05T22:50:46.434166Z","iopub.status.idle":"2022-04-05T22:50:46.445752Z","shell.execute_reply.started":"2022-04-05T22:50:46.434138Z","shell.execute_reply":"2022-04-05T22:50:46.444911Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def pre_process(X):\n    \n    # Fill columns with the least nulls first\n    #col_with_null = train_data.isnull().sum()\n    #col_with_null = col_with_null[col_with_null > 0]\n    #col_with_null = col_with_null.sort_values().index.tolist()\n    col_with_null = X.columns[X.isnull().any()].tolist()\n    for i in range(len(col_with_null)):\n        # col = current target column trying to fill null\n        col = col_with_null[i]\n        # other_col = other columns with null\n        # other_col = np.append(col_with_null[0:i], col_with_null[i+1:len(col_with_null)])\n        other_col = col_with_null[i+1:len(col_with_null)]\n        \n        # test = all rows with col = null\n        test = X.loc[X[col].isnull()]\n        idx = test.index\n        # train = all rows with col != null\n        train = X.drop(idx)\n        \n        # drop other columns with null from test and train\n        test = test.drop(columns=other_col)\n        train = train.drop(columns=other_col)\n        \n        # split data into feature and target\n        train_y = train[col]\n        train_x = train.drop(columns=col)\n        test_x = test.drop(columns=col)\n        \n        \n        # outlier detection on training set using Isolation forest\n        train_x = pd.concat([train_x, train_y], axis=1)\n        iso_forest = IsolationForest()\n        pred = iso_forest.fit_predict(train_x)\n        drop_idx = np.where(pred == -1)[0]\n        train_x = train_x.drop(labels=[x for x in drop_idx if x in train_x.index], axis=0)\n        #print(test_x.isnull().any())\n        train_y = train_x[col]\n        train_x = train_x.drop(columns=col)\n        \n        \"\"\"\n        m = train_x.shape[0]\n        all_x = pd.concat([train_x, test_x],ignore_index=True)\n        \n        obj_col = list(all_x.select_dtypes(include=['object']).columns)\n        \n        \n        # Pick columns with to many unique values to use as training data for clustering\n        clust_cols = []\n        for col in obj_col:\n            if(len(all_x[col].unique()) > 10):\n                clust_cols = clust_cols + [col]\n        \n        data = all_x[clust_cols]\n        kmeans = KMeans(n_clusters=10)\n        kmeans.fit(data)\n        all_x['Id'] = kmeans.labels_\n        obj_col = obj_col + ['Id']\n        train_x = all_x.iloc[:m,:]\n        test_x  = all_x.iloc[m:,:]\n        print(train_x.isnull().any())\n        print(train_y.isnull().any())\n        print(test_x.isnull().any())\n        \"\"\"\n        # Feature Selection\n        # Use mutual information to select features\n        mi = mutual_info_regression(train_x, train_y)\n        drop_idx = np.where(mi == 0)\n        train_x = train_x.drop(train_x.columns[drop_idx], axis=1)\n        test_x = test_x.drop(test_x.columns[drop_idx], axis=1)\n        \n        \"\"\"\n        #one-hot-encoding\n        obj_col = list(train_x.select_dtypes(include=['object']).columns)\n        \n        ohe_cols = []\n        for col in obj_col:\n            if(len(train_x[col].unique()) < 10):\n                ohe_cols = ohe_cols + [col]\n                \n        #Perform onehotencoding\n        encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n        encoded_train = encoder.fit_transform(train_x[ohe_cols])\n        encoded_test = encoder.transform(test_x[ohe_cols])\n        encoded_train = pd.DataFrame(encoded_train)\n        encoded_test = pd.DataFrame(encoded_test)\n        for col in encoded_train.columns:\n            train_x[col] = encoded_train[col]\n        for col in encoded_test.columns:\n            test_x[col] = encoded_test[col]\n        #train_x = pd.concat([train_x, encoded_train], axis=1, ignore_index=True)\n        #test_x  = pd.concat([test_x, encoded_test], axis=1, ignore_index=True)\n        \"\"\"\n        # Change dataframe to numpy\n        y_train = train_y.to_numpy()\n        x_train = train_x.to_numpy()\n        x_test  = test_x.to_numpy()\n        \"\"\"\n        # If the column is categorical, use one-vs-all classifier with stacking classifier\n        if(X[col].dtype == 'object'):\n            y_train = y_train.astype(float)\n            rf = RandomForestClassifier(n_estimators=10)\n            svc = SVC()\n            estimators = [('rf', rf), ('svc', svc)] \n            model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=2, n_jobs=-1)\n            result = cross_validate(model, x_train, y_train, return_estimator=True, cv=2)\n            max_index = result['test_score'].argmax()\n            model = result['estimator'][max_index]\n            if len(np.unique(y_train)) > 1:\n                model = OneVsRestClassifier(SVC()).fit(x_train, y_train)\n        else:   \n        # Otherwise, use stacking regressor\n            rf = RandomForestRegressor()\n            svr = SVR()\n            estimators = [('rf', rf), ('svr', svr)]\n            model = StackingRegressor(estimators=estimators, cv=2, n_jobs=-1)\n            result = cross_validate(model, x_train, y_train, return_estimator=True, cv=2)\n            max_index = result['test_score'].argmax()\n            model = result['estimator'][max_index]\n        \"\"\"\n        rf = RandomForestRegressor()\n        svr = SVR()\n        estimators = [('rf', rf), ('svr', svr)]\n        model = StackingRegressor(estimators=estimators, cv=2, n_jobs=-1)\n        result = cross_validate(model, x_train, y_train, return_estimator=True, cv=2)\n        max_index = result['test_score'].argmax()\n        model = result['estimator'][max_index]\n        test_x[col] = model.predict(x_test)\n        X.loc[idx, col] = test_x[col]\n        print(X[col].isnull().any())\n    return X","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:46.447290Z","iopub.execute_input":"2022-04-05T22:50:46.447526Z","iopub.status.idle":"2022-04-05T22:50:46.469477Z","shell.execute_reply.started":"2022-04-05T22:50:46.447497Z","shell.execute_reply":"2022-04-05T22:50:46.468120Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"all_data = pre_process(all_data)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:50:46.470858Z","iopub.execute_input":"2022-04-05T22:50:46.471438Z","iopub.status.idle":"2022-04-05T22:54:02.448696Z","shell.execute_reply.started":"2022-04-05T22:50:46.471395Z","shell.execute_reply":"2022-04-05T22:54:02.447484Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"obj_col = list(all_data.select_dtypes(include=['object']).columns)\nobj_col = obj_col + ['MSSubClass', 'YearBuilt', 'YearRemodAdd', 'MoSold', 'YrSold']\n# MSSubClass, YearBuilt, YearRemodAdd, MoSold, YrSold arre columns that should be categorical\n# but have numeric values","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:02.449897Z","iopub.execute_input":"2022-04-05T22:54:02.450186Z","iopub.status.idle":"2022-04-05T22:54:02.458564Z","shell.execute_reply.started":"2022-04-05T22:54:02.450151Z","shell.execute_reply":"2022-04-05T22:54:02.457649Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"for col in obj_col:\n    val_list = all_data[col].unique().tolist()\n    for val in val_list:\n        all_data.loc[all_data[col] == val, col] = round(val)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:02.459909Z","iopub.execute_input":"2022-04-05T22:54:02.460151Z","iopub.status.idle":"2022-04-05T22:54:15.530071Z","shell.execute_reply.started":"2022-04-05T22:54:02.460123Z","shell.execute_reply":"2022-04-05T22:54:15.529111Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"#train_X = all_data.iloc[:m,:]\n#test_data  = all_data.iloc[m:,:]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:15.531695Z","iopub.execute_input":"2022-04-05T22:54:15.532057Z","iopub.status.idle":"2022-04-05T22:54:15.536835Z","shell.execute_reply.started":"2022-04-05T22:54:15.532009Z","shell.execute_reply":"2022-04-05T22:54:15.535920Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# According to a post on discussion board, the sale price isn't in normal distribution\n# So by applying log transformation, we could make it nearr normal distribution\nplt.hist(train_y)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:15.538216Z","iopub.execute_input":"2022-04-05T22:54:15.538453Z","iopub.status.idle":"2022-04-05T22:54:15.804448Z","shell.execute_reply.started":"2022-04-05T22:54:15.538422Z","shell.execute_reply":"2022-04-05T22:54:15.803556Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"train_y = np.log(train_y)\nplt.hist(train_y)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:15.805909Z","iopub.execute_input":"2022-04-05T22:54:15.806219Z","iopub.status.idle":"2022-04-05T22:54:16.029254Z","shell.execute_reply.started":"2022-04-05T22:54:15.806173Z","shell.execute_reply":"2022-04-05T22:54:16.028426Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Pick columns with to many unique values to use as training data for clustering\nclust_cols = []\nfor col in obj_col:\n    if(len(all_data[col].unique()) > 10):\n        clust_cols = clust_cols + [col]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:16.030352Z","iopub.execute_input":"2022-04-05T22:54:16.031157Z","iopub.status.idle":"2022-04-05T22:54:16.052352Z","shell.execute_reply.started":"2022-04-05T22:54:16.031116Z","shell.execute_reply":"2022-04-05T22:54:16.051178Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"data = all_data[clust_cols]\nkmeans = KMeans(n_clusters=10)\nkmeans.fit(data)\nall_data['Id'] = kmeans.labels_\n#test = test_data[clust_cols]\n#test_data['Id'] = kmeans.predict(test)\n#all_data = all_data.drop(columns=clust_cols)\n#test_data = test_data.drop(columns=clust_cols)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:16.053695Z","iopub.execute_input":"2022-04-05T22:54:16.053957Z","iopub.status.idle":"2022-04-05T22:54:20.094382Z","shell.execute_reply.started":"2022-04-05T22:54:16.053927Z","shell.execute_reply":"2022-04-05T22:54:20.093662Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"#for col in clust_cols:\n#    obj_col.remove(col)\nobj_col = obj_col + ['Id']","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:20.099129Z","iopub.execute_input":"2022-04-05T22:54:20.101606Z","iopub.status.idle":"2022-04-05T22:54:20.109067Z","shell.execute_reply.started":"2022-04-05T22:54:20.101514Z","shell.execute_reply":"2022-04-05T22:54:20.108295Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"#Perform onehotencoding\nencoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nencoded_all = encoder.fit_transform(all_data[obj_col])\n#encoded_test = encoder.fit_transform(test_data[obj_col])\nencoded_all = pd.DataFrame(encoded_all)\nencoded_col = list(encoded_all.columns)\nall_data = pd.concat([all_data, encoded_all], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:20.116080Z","iopub.execute_input":"2022-04-05T22:54:20.116520Z","iopub.status.idle":"2022-04-05T22:54:20.226342Z","shell.execute_reply.started":"2022-04-05T22:54:20.116487Z","shell.execute_reply":"2022-04-05T22:54:20.225561Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"#all_data = all_data.drop(columns=obj_col)\n#test_data = test_data.drop(columns=obj_col)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:20.227530Z","iopub.execute_input":"2022-04-05T22:54:20.227918Z","iopub.status.idle":"2022-04-05T22:54:20.231137Z","shell.execute_reply.started":"2022-04-05T22:54:20.227887Z","shell.execute_reply":"2022-04-05T22:54:20.230474Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n# Get skewed data with skewness larger than 0.5, apply log transformation\nfrom scipy.stats import skew\ndef get_skew(x):\n    return skew(x)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:20.232280Z","iopub.execute_input":"2022-04-05T22:54:20.232512Z","iopub.status.idle":"2022-04-05T22:54:20.250782Z","shell.execute_reply.started":"2022-04-05T22:54:20.232485Z","shell.execute_reply":"2022-04-05T22:54:20.249853Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nskewed = all_data[all_data.columns[~all_data.columns.isin(obj_col + encoded_col)]].apply(get_skew)\nskewed = skewed[skewed > 0.5]\nfor col in skewed.index:\n    all_data[col] = np.log1p(all_data[col])\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:20.256531Z","iopub.execute_input":"2022-04-05T22:54:20.257210Z","iopub.status.idle":"2022-04-05T22:54:20.268120Z","shell.execute_reply.started":"2022-04-05T22:54:20.257172Z","shell.execute_reply":"2022-04-05T22:54:20.267100Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"all_data.isnull().any().unique()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:20.269441Z","iopub.execute_input":"2022-04-05T22:54:20.269941Z","iopub.status.idle":"2022-04-05T22:54:20.308419Z","shell.execute_reply.started":"2022-04-05T22:54:20.269901Z","shell.execute_reply":"2022-04-05T22:54:20.307414Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n# Perform Feature Scaling on non-categorical data\n# Standard, MinMax, and MaxAbs suffer from outlies\n# Robust and QuantileTransformer don't suffer from outliers, but QuatileTransformer will collapse outliers\n# So we choose RobustScaler\nfrom sklearn.preprocessing import RobustScaler\nnon_cat_col = [i for i in list(all_data.columns) if i not in obj_col]\nfor col in encoded_col:\n    non_cat_col.remove(col)\nfor col in non_cat_col:\n    scaler = RobustScaler()\n    all_data[col] = scaler.fit_transform(all_data[[col]])\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:20.309757Z","iopub.execute_input":"2022-04-05T22:54:20.310043Z","iopub.status.idle":"2022-04-05T22:54:20.316853Z","shell.execute_reply.started":"2022-04-05T22:54:20.310010Z","shell.execute_reply":"2022-04-05T22:54:20.316162Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"#all_data.isnull().any().unique()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:20.318274Z","iopub.execute_input":"2022-04-05T22:54:20.319198Z","iopub.status.idle":"2022-04-05T22:54:20.335980Z","shell.execute_reply.started":"2022-04-05T22:54:20.319162Z","shell.execute_reply":"2022-04-05T22:54:20.334904Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"train_X = all_data.iloc[:m,:]\ntest_data  = all_data.iloc[m:,:]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:20.337560Z","iopub.execute_input":"2022-04-05T22:54:20.338134Z","iopub.status.idle":"2022-04-05T22:54:20.351124Z","shell.execute_reply.started":"2022-04-05T22:54:20.338083Z","shell.execute_reply":"2022-04-05T22:54:20.350351Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"X_train = train_X.to_numpy()\n#X_train = np.hstack((X_train, encoded_train))\ny_train = train_y.to_numpy()\nX_test  = test_data.to_numpy()\n#X_test = np.hstack((X_test, encoded_test))","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:20.352774Z","iopub.execute_input":"2022-04-05T22:54:20.353689Z","iopub.status.idle":"2022-04-05T22:54:20.468213Z","shell.execute_reply.started":"2022-04-05T22:54:20.353636Z","shell.execute_reply":"2022-04-05T22:54:20.467017Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Feature Selection\n# Use mutual information to select features\nmi = mutual_info_regression(train_X, train_y)\ndrop_idx = np.where(mi == 0)\nall_data = all_data.drop(all_data.columns[drop_idx], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:20.469687Z","iopub.execute_input":"2022-04-05T22:54:20.470033Z","iopub.status.idle":"2022-04-05T22:54:26.062905Z","shell.execute_reply.started":"2022-04-05T22:54:20.469986Z","shell.execute_reply":"2022-04-05T22:54:26.061993Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n# For some reason, BsmtUnfSF contains null, so just drop it for now\nall_data.loc[0, all_data.isnull().any()]\nall_data = all_data.drop(columns=['BsmtUnfSF'])\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:26.064302Z","iopub.execute_input":"2022-04-05T22:54:26.064553Z","iopub.status.idle":"2022-04-05T22:54:26.071087Z","shell.execute_reply.started":"2022-04-05T22:54:26.064521Z","shell.execute_reply":"2022-04-05T22:54:26.070149Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n# Add polynomial features, only get top 20 in correlation with sale price\nfrom sklearn.preprocessing import PolynomialFeatures\npoly = PolynomialFeatures(2, interaction_only=True)\npoly_feat = pd.DataFrame(poly.fit_transform(all_data.iloc[:,:25]), columns=poly.get_feature_names_out(list(all_data.columns[:25])))\npoly_feat_train = poly_feat.iloc[:m, 26:]\ncorr = poly_feat_train.corrwith(train_y, axis=0)\ncorr = corr.sort_values(ascending=False)\ncorr = corr[:20]\npoly_feat = poly_feat[corr.index]\nall_data = pd.concat([all_data, poly_feat], axis=1)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:26.072930Z","iopub.execute_input":"2022-04-05T22:54:26.073262Z","iopub.status.idle":"2022-04-05T22:54:26.089019Z","shell.execute_reply.started":"2022-04-05T22:54:26.073216Z","shell.execute_reply":"2022-04-05T22:54:26.087954Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"train_X = all_data.iloc[:m,:]\ntest_data  = all_data.iloc[m:,:]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:26.090354Z","iopub.execute_input":"2022-04-05T22:54:26.090939Z","iopub.status.idle":"2022-04-05T22:54:26.106119Z","shell.execute_reply.started":"2022-04-05T22:54:26.090897Z","shell.execute_reply":"2022-04-05T22:54:26.104916Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# outlier detection on training set using Isolation forest\ntrain_X = pd.concat([train_X, train_y], axis=1)\niso_forest = IsolationForest(random_state=0)\npred = iso_forest.fit_predict(train_X)\ndrop_idx = np.where(pred == -1)[0]\ntrain_X = train_X.drop(labels=drop_idx, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:26.107671Z","iopub.execute_input":"2022-04-05T22:54:26.108014Z","iopub.status.idle":"2022-04-05T22:54:27.041900Z","shell.execute_reply.started":"2022-04-05T22:54:26.107969Z","shell.execute_reply":"2022-04-05T22:54:27.040807Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ntrain_y = train_X['SalePrice']\ntrain_X = train_X.drop(columns=['SalePrice'])\nall_data = pd.concat([train_X, test_data],ignore_index=True)\nfor col in all_data.columns:\n    if(type(col) == int):\n        col_str = str(col)\n        all_data = all_data.rename(columns={col: col_str})\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:27.043453Z","iopub.execute_input":"2022-04-05T22:54:27.043811Z","iopub.status.idle":"2022-04-05T22:54:27.050230Z","shell.execute_reply.started":"2022-04-05T22:54:27.043775Z","shell.execute_reply":"2022-04-05T22:54:27.049201Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"\"\"\"\ntrain_X = all_data.iloc[:m,:]\ntest_data  = all_data.iloc[m:,:]\ntrain_X = pd.concat([train_X, train_y], axis=1)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:27.051736Z","iopub.execute_input":"2022-04-05T22:54:27.052075Z","iopub.status.idle":"2022-04-05T22:54:27.064411Z","shell.execute_reply.started":"2022-04-05T22:54:27.052029Z","shell.execute_reply":"2022-04-05T22:54:27.063245Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"train_y = train_X['SalePrice']\ntrain_X = train_X.drop(columns=['SalePrice'])","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:27.065953Z","iopub.execute_input":"2022-04-05T22:54:27.066217Z","iopub.status.idle":"2022-04-05T22:54:27.079404Z","shell.execute_reply.started":"2022-04-05T22:54:27.066180Z","shell.execute_reply":"2022-04-05T22:54:27.078156Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"X_train = train_X.to_numpy()\ny_train = train_y.to_numpy()\nX_test = test_data.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:27.081242Z","iopub.execute_input":"2022-04-05T22:54:27.081592Z","iopub.status.idle":"2022-04-05T22:54:27.190383Z","shell.execute_reply.started":"2022-04-05T22:54:27.081524Z","shell.execute_reply":"2022-04-05T22:54:27.189651Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Use grid search to get the optimal hyperparameters\n\"\"\"\nn_estimators = [100,200,300,400,500]\nmax_depth = [3,4,5,10]\nlearning_rate=['constant', 'optimal', 'invscaling', 'adaptive']\nmin_samples_split = [2,4,6,8,10]\nmin_samples_leaf = [2,4,6,8,10]\n\ncoef0=[0.0, 0.1, 0.3, 0.5, 0.7, 1]\nshrinking=[True,False]\nC = [1, 2, 3]\nkernel=['linear', 'poly', 'rbf', 'sigmoid', 'precompute']\ndegree=[1, 2, 3]\ngamma=['scale', 'auto']\n\nselection = ['cyclic', 'random']\neps = [1e-3,  1e-4, 1e-5]\ntol=[1e-3, 1e-4, 1e-5, 1e-6]\nmax_iter = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\ncv = [2,3,4,5]\n\nopt_dict = {\n            'max_iter': max_iter,\n            'tol': tol,\n            'eps': eps,\n            'tol': tol,\n            'cv': cv}\n\nmodel = LassoCV()\n\nmodel = RandomizedSearchCV(model, opt_dict, n_jobs=1, cv=2)\nmodel.fit(X_train,y_train)\nprint(model.best_score_)\nprint(model.best_params_)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:27.191912Z","iopub.execute_input":"2022-04-05T22:54:27.192421Z","iopub.status.idle":"2022-04-05T22:54:27.199662Z","shell.execute_reply.started":"2022-04-05T22:54:27.192375Z","shell.execute_reply":"2022-04-05T22:54:27.198977Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"xgbr = xgb.XGBRegressor(subsample=0.9, num_boost_round=25, n_estimators=300, max_depth=3, eta=0.05, colsample_bytree=0.9)\nlgbm = LGBMRegressor(n_estimators=300, max_depth=3, learning_rate=0.1)\ncb = CatBoostRegressor()\nlr = LinearRegression()\nkr = KernelRidge()\nlcv = LassoCV(tol=1e-05, max_iter=600,eps=1e-05, cv=5)\nen = ElasticNet(selection='random', normalize=False, max_iter=500, l1_ratio=0.7, alpha=1)\nbr = BayesianRidge(tol=0.001, normalize=True, n_iter=300)\nsvr = SVR(tol=0.001, shrinking=False, max_iter=500, kernel='rbf', gamma='auto', degree=2, coef0=0.3, C=1)\nrf = RandomForestRegressor(n_estimators=100, min_samples_split=5, min_samples_leaf=1, max_features='sqrt', max_depth=100)\ngb = GradientBoostingRegressor(n_estimators=700, min_samples_split=10, min_samples_leaf=4, max_features='log2', max_depth=30)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:27.200822Z","iopub.execute_input":"2022-04-05T22:54:27.201646Z","iopub.status.idle":"2022-04-05T22:54:27.216366Z","shell.execute_reply.started":"2022-04-05T22:54:27.201595Z","shell.execute_reply":"2022-04-05T22:54:27.215230Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":" estimators = [\n    ('xgbr', xgbr),\n    ('lgbm', lgbm),\n    ('cb', cb),\n    ('rf', rf),\n    ('gb', gb)\n\n    #('lr', lr)\n    #('kr', kr),\n    #('en', en),\n    #('br', br)\n    #('svr', svr)\n    #('lcv', lcv)\n]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:27.217704Z","iopub.execute_input":"2022-04-05T22:54:27.218036Z","iopub.status.idle":"2022-04-05T22:54:27.234175Z","shell.execute_reply.started":"2022-04-05T22:54:27.217992Z","shell.execute_reply":"2022-04-05T22:54:27.233294Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"model = StackingRegressor(estimators=estimators, cv=2, n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:27.235546Z","iopub.execute_input":"2022-04-05T22:54:27.236324Z","iopub.status.idle":"2022-04-05T22:54:27.248337Z","shell.execute_reply.started":"2022-04-05T22:54:27.236282Z","shell.execute_reply":"2022-04-05T22:54:27.247635Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"result = cross_validate(model, X_train, y_train, return_estimator=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:54:27.249358Z","iopub.execute_input":"2022-04-05T22:54:27.249747Z","iopub.status.idle":"2022-04-05T22:56:36.683541Z","shell.execute_reply.started":"2022-04-05T22:54:27.249708Z","shell.execute_reply":"2022-04-05T22:56:36.682785Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"max_index = result['test_score'].argmax()\nmodel = result['estimator'][max_index]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:56:36.684902Z","iopub.execute_input":"2022-04-05T22:56:36.685875Z","iopub.status.idle":"2022-04-05T22:56:36.690559Z","shell.execute_reply.started":"2022-04-05T22:56:36.685832Z","shell.execute_reply":"2022-04-05T22:56:36.689641Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"output = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:56:36.691801Z","iopub.execute_input":"2022-04-05T22:56:36.692116Z","iopub.status.idle":"2022-04-05T22:56:37.177409Z","shell.execute_reply.started":"2022-04-05T22:56:36.692084Z","shell.execute_reply":"2022-04-05T22:56:37.176639Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"output = np.exp(output)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:56:37.178641Z","iopub.execute_input":"2022-04-05T22:56:37.178864Z","iopub.status.idle":"2022-04-05T22:56:37.183185Z","shell.execute_reply.started":"2022-04-05T22:56:37.178837Z","shell.execute_reply":"2022-04-05T22:56:37.182089Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"index_array = np.zeros(np.shape(output))\nfor i in range(np.shape(index_array)[0]):\n    index_array[i] = 1461+i\nindex_array = np.reshape(index_array, (np.shape(index_array)[0],1))\noutput = np.reshape(output, (np.shape(output)[0],1))","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:56:37.184666Z","iopub.execute_input":"2022-04-05T22:56:37.185065Z","iopub.status.idle":"2022-04-05T22:56:37.196468Z","shell.execute_reply.started":"2022-04-05T22:56:37.185009Z","shell.execute_reply":"2022-04-05T22:56:37.195923Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"index = pd.DataFrame(index_array, columns = ['Id'], dtype=int)\nsale = pd.DataFrame(output, columns = ['SalePrice'], dtype=float)\noutput_df = index.join(sale)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:56:37.198527Z","iopub.execute_input":"2022-04-05T22:56:37.199253Z","iopub.status.idle":"2022-04-05T22:56:37.212510Z","shell.execute_reply.started":"2022-04-05T22:56:37.199205Z","shell.execute_reply":"2022-04-05T22:56:37.211701Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"output_df.to_csv('output.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:56:37.213554Z","iopub.execute_input":"2022-04-05T22:56:37.214124Z","iopub.status.idle":"2022-04-05T22:56:37.228410Z","shell.execute_reply.started":"2022-04-05T22:56:37.214087Z","shell.execute_reply":"2022-04-05T22:56:37.227592Z"},"trusted":true},"execution_count":66,"outputs":[]}]}