{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-05T22:48:20.881477Z","iopub.execute_input":"2022-04-05T22:48:20.881856Z","iopub.status.idle":"2022-04-05T22:48:20.910714Z","shell.execute_reply.started":"2022-04-05T22:48:20.881752Z","shell.execute_reply":"2022-04-05T22:48:20.909835Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\ntest_data = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:20.912303Z","iopub.execute_input":"2022-04-05T22:48:20.912582Z","iopub.status.idle":"2022-04-05T22:48:20.982056Z","shell.execute_reply.started":"2022-04-05T22:48:20.912530Z","shell.execute_reply":"2022-04-05T22:48:20.981107Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_y = train_data[['SalePrice']]\ntrain_X = train_data.drop(['SalePrice'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:20.983152Z","iopub.execute_input":"2022-04-05T22:48:20.983751Z","iopub.status.idle":"2022-04-05T22:48:20.998119Z","shell.execute_reply.started":"2022-04-05T22:48:20.983712Z","shell.execute_reply":"2022-04-05T22:48:20.997111Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Choose features based on correlation with SalePrice\n# Weak correlation [-0.5, 0.5]\ncorr = train_X.corrwith(train_data['SalePrice'])\ncorr_min = corr.min() + corr.std()\ncorr_max = corr.max() - corr.std()\ncorr0 = corr[corr > 0.5]\ncorr1 = corr[corr < -0.5]\ncorr = pd.concat([corr0, corr1])\ncolumn = corr.index","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:21.000278Z","iopub.execute_input":"2022-04-05T22:48:21.000760Z","iopub.status.idle":"2022-04-05T22:48:21.033198Z","shell.execute_reply.started":"2022-04-05T22:48:21.000725Z","shell.execute_reply":"2022-04-05T22:48:21.032438Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_X = train_X[column]\ntest_data = test_data[column]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:21.034716Z","iopub.execute_input":"2022-04-05T22:48:21.035457Z","iopub.status.idle":"2022-04-05T22:48:21.043431Z","shell.execute_reply.started":"2022-04-05T22:48:21.035414Z","shell.execute_reply":"2022-04-05T22:48:21.042532Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Get object data columns and numeric data columns\nobj_col = list(train_X.select_dtypes(include=['object']).columns)\nnum_col = list(train_X.select_dtypes(include=['int','float']).columns)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:21.045425Z","iopub.execute_input":"2022-04-05T22:48:21.046125Z","iopub.status.idle":"2022-04-05T22:48:21.059153Z","shell.execute_reply.started":"2022-04-05T22:48:21.046073Z","shell.execute_reply":"2022-04-05T22:48:21.058268Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Transform object data to numeric for both train and test data (fill nan with 0)\nfor col in obj_col:\n    val = np.stack(train_X[col].unique())\n    for i in range(len(val)):\n        if val[i] == 'nan':\n            val = np.delete(val, i)\n            break\n    train_X[col] = train_X[col].fillna(0)\n    test_data[col] = test_data[col].fillna(0)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:21.060716Z","iopub.execute_input":"2022-04-05T22:48:21.061158Z","iopub.status.idle":"2022-04-05T22:48:21.066995Z","shell.execute_reply.started":"2022-04-05T22:48:21.061125Z","shell.execute_reply":"2022-04-05T22:48:21.066316Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Fill nan in numeric columns with the mean value of that column\nfor col in num_col:\n    train_X[col].fillna(value=train_X[col].mean(), inplace=True)\n    test_data[col].fillna(value=test_data[col].mean(), inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:21.068338Z","iopub.execute_input":"2022-04-05T22:48:21.068829Z","iopub.status.idle":"2022-04-05T22:48:21.098342Z","shell.execute_reply.started":"2022-04-05T22:48:21.068796Z","shell.execute_reply":"2022-04-05T22:48:21.097330Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Remove outlier for all the numeric columns\n# Use Inter-Quartile Range (IQR) proximity rule.\n# The data points which fall below Q1 – 1.5 IQR or above Q3 + 1.5 IQR are outliers.\n# where Q1 and Q3 are the 25th and 75th percentile of the dataset respectively,\n# and IQR represents the inter-quartile range and given by Q3 – Q1.\n\"\"\"\nfor col in train_X.columns:\n    q1 = train_X[col].quantile(0.25)\n    q3 = train_X[col].quantile(0.75)\n    iqr = q3 - q1\n    upper_bound = q3 + 1.5 * (iqr)\n    lower_bound = q1 - 1.5 * (iqr)\n    train_X.loc[train_X[col] < lower_bound, col] = np.nan\n    train_X.loc[train_X[col] > upper_bound, col] = np.nan\n    mean = train_X[col].mean()\n    train_X[col] = train_X[col].fillna(mean)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:21.099900Z","iopub.execute_input":"2022-04-05T22:48:21.100374Z","iopub.status.idle":"2022-04-05T22:48:21.108966Z","shell.execute_reply.started":"2022-04-05T22:48:21.100339Z","shell.execute_reply":"2022-04-05T22:48:21.108142Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Adding polynomial features\ncol = train_X.columns\nnum = len(col)\nfor i in range(num):\n    for j in range(num):\n        new_col = col[i] + \"_\" + col[j]\n        train_X[new_col] = train_X[col[i]] * train_X[col[j]]\n        test_data[new_col] = test_data[col[i]] * test_data[col[j]]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:21.111747Z","iopub.execute_input":"2022-04-05T22:48:21.112130Z","iopub.status.idle":"2022-04-05T22:48:21.257816Z","shell.execute_reply.started":"2022-04-05T22:48:21.112081Z","shell.execute_reply":"2022-04-05T22:48:21.256665Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# After adding polynomial data, keep features with correlation larger than 0.7\ncorr = train_X.corrwith(train_data['SalePrice'])\ncorr_min = corr.min() + corr.std()\ncorr_max = corr.max() - corr.std()\ncorr = corr[corr > 0.7]\ncolumn = corr.index\ntrain_X = train_X[column]\ntest_data = test_data[column]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:21.259046Z","iopub.execute_input":"2022-04-05T22:48:21.259758Z","iopub.status.idle":"2022-04-05T22:48:21.322381Z","shell.execute_reply.started":"2022-04-05T22:48:21.259714Z","shell.execute_reply":"2022-04-05T22:48:21.321549Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Converting dataframe to numpy array\nX_train = train_X.to_numpy()\ny_train = train_y.to_numpy()\nX_test = test_data.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:21.323485Z","iopub.execute_input":"2022-04-05T22:48:21.324230Z","iopub.status.idle":"2022-04-05T22:48:21.329875Z","shell.execute_reply.started":"2022-04-05T22:48:21.324192Z","shell.execute_reply":"2022-04-05T22:48:21.328799Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_validate\nfrom sklearn.tree import DecisionTreeRegressor\n\nmodel = DecisionTreeRegressor()\nresult = cross_validate(model, X_train, y_train, return_estimator=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:21.331055Z","iopub.execute_input":"2022-04-05T22:48:21.332072Z","iopub.status.idle":"2022-04-05T22:48:22.672698Z","shell.execute_reply.started":"2022-04-05T22:48:21.332017Z","shell.execute_reply":"2022-04-05T22:48:22.671758Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"max_index = result['test_score'].argmax()\nmodel = result['estimator'][max_index]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:22.674088Z","iopub.execute_input":"2022-04-05T22:48:22.674438Z","iopub.status.idle":"2022-04-05T22:48:22.679952Z","shell.execute_reply.started":"2022-04-05T22:48:22.674389Z","shell.execute_reply":"2022-04-05T22:48:22.678842Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"output = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:22.681360Z","iopub.execute_input":"2022-04-05T22:48:22.681874Z","iopub.status.idle":"2022-04-05T22:48:22.691269Z","shell.execute_reply.started":"2022-04-05T22:48:22.681822Z","shell.execute_reply":"2022-04-05T22:48:22.690610Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"index_array = np.zeros(np.shape(output))\nfor i in range(np.shape(index_array)[0]):\n    index_array[i] = 1461+i\nindex_array = np.reshape(index_array, (np.shape(index_array)[0],1))\noutput = np.reshape(output, (np.shape(output)[0],1))\noutput = np.hstack((index_array,output))","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:22.692481Z","iopub.execute_input":"2022-04-05T22:48:22.693185Z","iopub.status.idle":"2022-04-05T22:48:22.701537Z","shell.execute_reply.started":"2022-04-05T22:48:22.693151Z","shell.execute_reply":"2022-04-05T22:48:22.700896Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"output_df = pd.DataFrame(output, columns = ['Id', 'SalePrice'], dtype=int)\noutput_df.to_csv('output.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:48:22.702866Z","iopub.execute_input":"2022-04-05T22:48:22.703342Z","iopub.status.idle":"2022-04-05T22:48:22.719908Z","shell.execute_reply.started":"2022-04-05T22:48:22.703308Z","shell.execute_reply":"2022-04-05T22:48:22.719243Z"},"trusted":true},"execution_count":17,"outputs":[]}]}